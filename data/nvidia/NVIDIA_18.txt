                                                                                                
 While chipmarkers like Intel and AMD's gross margins are lower than 50 percent, Nvidia sits atop the rest at around 80 percent.   
Nvidia's relentless march in the stock market shows that most investors believe it has a monopoly in the artificial intelligence (AI) chip market. But that won't cut it for the $3 trillion company when it comes to the Indian government's billion-dollar plan to make graphics processing units (GPUs) available to startups and researchers domestically."As a procurement rule, we will never go with one brand. We are looking for certain functions in the chips and we know these are fast changing situations. Our procurement will be brand neutral," said a source close to the developments.Story continues below AdvertisementRemove Ad"There are other companies that are competitors who are coming into the market. That's what brings pricing efficiency," the source added.Being the AI chip supplier to Meta and Microsoft-backed OpenAI has not only helped Nvidia corner almost all of the AI chip demand as yet, but also maintain its pricing power much ahead of its competitors in the market.While chipmarkers like Intel and AMD's gross margins are lower than 50 percent, Nvidia sits atop the rest at around 80 percent. Related stories Sam Altman says Airbnb CEO helped OpenAI grow: Brian Chesky was 'almost always right'French competition authority confirms investigation into NvidiaWorld Street | Google eyes Wiz for $23 bn; Goldman Sachs challenges Fed; Kuwait announces ‘giant�... However, industry experts believe that Nvidia's dominance could soon be on the wane as players like Intel and AMD have recently unveiled AI chips that are priced substantially lower and have also been seen to perform functions better in some cases.Also read: Can NVIDIA's AI chip reign continue? A look at its rise and potential challengesFor example, Intel's latest pack-of-eight AI chips called Gaudi 3 costs $125,000, whereas a similar combo of Nvidia's H100 chips may cost upwards of $300,000.Story continues below AdvertisementRemove AdAnother important factor that might pull down prices is the move by big tech firms like Google, Meta and Amazon  to develop their own AI chips in-house. Consequently, a glut of GPUs in the market would lead to a crash in their prices if demand does not rise in lockstep.A second source close to the government's GPU procurement plans seemed to be attuned to such possibilities."It's a very cyclical industry. Investment will go up and prices will crash. In the last two or three years, the prices have gone up and heavy investments have been made in the chip industry. Actually, that's one of the problems now," he said.Moneycontrol reported earlier this week that the Ministry of Electronics and Information Technology (MeitY) is expected to roll out a tender for procuring GPUs in the next fortnight.This decision was taken in a review meeting that MeitY held on ongoing projects recently. Under the Rs 10,732 crore IndiaAI Mission, the government plans to use around Rs 8,000 crore to provide viability gap funding for GPU-based computing infrastructure or offer it through a voucher system to startups and researchers.The forthcoming request for proposal (RFP) will outline the government's initial GPU capacity requirements and the timeline for deployment.The RFP is also expected to clarify whether data centres/cloud service providers in other countries will be eligible to participate in the bidding process.The industry has advised the government that it should not invest directly in the capex for GPUs. It has suggested that the government should subscribe to the GPU capacity put up by domestic data centre companies and allocate it to startups, rather than fund capex.Apart from other hindrances in building home-grown foundational models, India lacks domestic compute capacity. To solve that issue, one of the aims of the IndiaAI mission is to make over 10,000 GPUs available in India. IndiaAI is the government's AI ecosystem building initiative.GPUs, which are primarily designed to render images and videos quickly and efficiently, are the hardware on top of which AI models can be trained. They are primarily housed in a data centre.
       